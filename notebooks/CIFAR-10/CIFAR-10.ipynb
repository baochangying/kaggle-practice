{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef7335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86045bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/raw/cifar-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f54c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_labels(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "    tokens = [l.rstrip().split(',') for l in lines]\n",
    "    return dict(((name,label) for name,label in tokens))\n",
    "labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3e023",
   "metadata": {},
   "source": [
    "将数据集划分为训练集、验证集和测试集。这里演示所以是copy操作,正常会用cut操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a44c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyfile(filename, target_dir):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    shutil.copy(filename, target_dir)\n",
    "\n",
    "\n",
    "def reorg_train_valid(data_dir, labels, valid_ratio):\n",
    "    n = collections.Counter(labels.values()).most_common()[-1][1]\n",
    "    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n",
    "    label_count = {}\n",
    "    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n",
    "        label = labels[train_file.split('.')[0]]\n",
    "        fname = os.path.join(data_dir, 'train', train_file)\n",
    "        copyfile(fname, os.path.join(data_dir, 'train_valid_test', 'train_valid', label))\n",
    "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
    "            copyfile(fname, os.path.join(data_dir, 'train_valid_test', 'valid', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            copyfile(fname, os.path.join(data_dir, 'train_valid_test', 'train', label))\n",
    "    return n_valid_per_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997a7ed",
   "metadata": {},
   "source": [
    "在预测期间整理测试集,方便读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorg_test(data_dir):\n",
    "    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n",
    "        copyfile(os.path.join(data_dir, 'test', test_file), \n",
    "                 os.path.join(data_dir, 'train_valid_test', 'test', 'unknown'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b576b2",
   "metadata": {},
   "source": [
    "调用前面定义的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorg_cifar10_data(data_dir, valid_radio):\n",
    "    labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
    "    reorg_train_valid(data_dir, labels, valid_radio)\n",
    "    reorg_test(data_dir)\n",
    "    \n",
    "batch_size = 128\n",
    "valid_radio = 0.1\n",
    "reorg_cifar10_data(data_dir, valid_radio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75efb4",
   "metadata": {},
   "source": [
    "图像增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadd67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(40),\n",
    "    torchvision.transforms.RandomResizedCrop(32, \n",
    "                                             scale=(0.64,1.0), \n",
    "                                             ratio=(1.0,1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331d25b",
   "metadata": {},
   "source": [
    "读取由原始图像组成的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a158f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_valid_ds = [\n",
    "    torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train_valid_test', folder),\n",
    "        transform=transform_train) for folder in ['train', 'train_valid']\n",
    "]\n",
    "\n",
    "valid_ds, test_ds = [\n",
    "    torchvision.datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train_valid_test', folder),\n",
    "    transform=transform_test) for folder in ['valid', 'test']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d566304",
   "metadata": {},
   "source": [
    "指定上面定义的所有图像做数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, train_valid_iter = [\n",
    "    torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size, \n",
    "        shuffle=True, \n",
    "        drop_last=True\n",
    "        ) for dataset in (train_ds, train_valid_ds)\n",
    "]\n",
    "\n",
    "valid_iter = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size, shuffle=False, drop_last=True\n",
    ")\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a4eb8",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec9df6",
   "metadata": {},
   "source": [
    "使用torchvision定义的resnet18模型\n",
    "\n",
    "TODO 手动实现ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "def get_net():\n",
    "    num_classes = 10\n",
    "    # 加载预定义的 ResNet-18 模型\n",
    "    net = resnet18(pretrained=False)  # pretrained=False 表示不加载预训练权重\n",
    "    # 修改最后一层全连接层以适应我们的类别数\n",
    "    net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "    return net\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5aff2b",
   "metadata": {},
   "source": [
    "训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay):\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(trainer, step_size=lr_period, gamma=lr_decay)\n",
    "    num_batches, timer = len(train_iter), d2l.Timer()\n",
    "    legend = ['train loss', 'train acc']\n",
    "    if valid_iter is not None:\n",
    "        legend.append('valid acc')\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1], legend=legend)\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        metric = d2l.Accumulator(3)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = d2l.train_batch_ch13(net, features, labels, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0])\n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(\n",
    "                    epoch + (i + 1) / num_batches,\n",
    "                    (metric[0] / metric[2], metric[1] / metric[2], None))\n",
    "        if valid_iter is not None:\n",
    "            valid_acc = d2l.evaluate_accuracy_gpu(net, valid_iter)\n",
    "            animator.add(epoch + 1, (None, None, valid_acc))\n",
    "        scheduler.step()\n",
    "    measures = (f'train loss {metric[0] / metric[2]:.3f}, '\n",
    "                f'train acc {metric[1] / metric[2]:.3f}')\n",
    "    if valid_iter is not None:\n",
    "        measures += f', valid acc {valid_acc:.3f}'\n",
    "    print(measures + f'\\n{metric[2] * num_epochs / timer.sum():.1f} examples/sec on {str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e74cff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "from tqdm import tqdm  # 进度条（可选）\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay):\n",
    "    # 初始化优化器和学习率调度器\n",
    "    trainer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "    scheduler = optim.lr_scheduler.StepLR(trainer, step_size=lr_period, gamma=lr_decay)\n",
    "    \n",
    "    # 多 GPU 并行（如果可用）\n",
    "    if len(devices) > 1:\n",
    "        net = nn.DataParallel(net, device_ids=devices)\n",
    "    net.to(devices[0])\n",
    "\n",
    "    # 记录训练过程\n",
    "    train_loss, train_acc, val_acc = [], [], []\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    # 计时器\n",
    "    start_time = time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 训练模式\n",
    "        epoch_loss, epoch_acc, total_samples = 0.0, 0.0, 0\n",
    "\n",
    "        # 使用 tqdm 显示进度条（可选）\n",
    "        for features, labels in tqdm(train_iter, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            features, labels = features.to(devices[0]), labels.to(devices[0])\n",
    "            \n",
    "            # 前向计算\n",
    "            outputs = net(features)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            \n",
    "            # 反向传播\n",
    "            trainer.zero_grad()\n",
    "            loss.backward()\n",
    "            trainer.step()\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            \n",
    "            # 累积统计量\n",
    "            batch_size = labels.size(0)\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "            epoch_acc += correct\n",
    "            total_samples += batch_size\n",
    "\n",
    "        # 计算平均损失和准确率\n",
    "        avg_loss = epoch_loss / total_samples\n",
    "        avg_acc = epoch_acc / total_samples\n",
    "        train_loss.append(avg_loss)\n",
    "        train_acc.append(avg_acc)\n",
    "        \n",
    "        # 验证集评估\n",
    "        if valid_iter is not None:\n",
    "            net.eval()  # 评估模式\n",
    "            correct, total = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for features, labels in valid_iter:\n",
    "                    features, labels = features.to(devices[0]), labels.to(devices[0])\n",
    "                    outputs = net(features)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "            val_accuracy = correct / total\n",
    "            val_acc.append(val_accuracy)\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "\n",
    "        # 打印日志\n",
    "        log = f'Epoch {epoch+1}/{num_epochs}: train loss={avg_loss:.3f}, train acc={avg_acc:.3f}'\n",
    "        if valid_iter is not None:\n",
    "            log += f', valid acc={val_accuracy:.3f}'\n",
    "        print(log)\n",
    "\n",
    "        # 动态绘制曲线（替代 d2l.Animator）\n",
    "        plt.clf()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_loss, label='train loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_acc, label='train acc')\n",
    "        if valid_iter is not None:\n",
    "            plt.plot(val_acc, label='valid acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.pause(0.1)  # 动态更新\n",
    "\n",
    "    # 计算吞吐量\n",
    "    total_time = time() - start_time\n",
    "    total_samples = len(train_iter.dataset) * num_epochs\n",
    "    throughput = total_samples / total_time\n",
    "    print(f'{throughput:.1f} examples/sec on {devices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96000fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():\n",
    "    devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "devices, num_epochs, lr, wd = try_all_gpus(), 20, 2e-4, 5e-4\n",
    "lr_period, lr_decay, net = 4, 0.9,get_net()\n",
    "train(net, train_iter, test_iter, num_epochs, lr, wd, devices, lr_period, lr_decay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
